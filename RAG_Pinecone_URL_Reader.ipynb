{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-adeleke1/Association_of_Data_Scientists/blob/main/RAG_Pinecone_URL_Reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "3NRqAYE51gLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai langchain-community unstructured==0.7.12 pinecone openai tiktoken -q\n",
        "!pip install langchain langchain-pinecone -q"
      ],
      "metadata": {
        "id": "V5S6OD9U-gRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1a45df-c541-4c20-995c-e7fffbe30476"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for standardwebhooks (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dependencies"
      ],
      "metadata": {
        "id": "T4jIRdQ81k1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.vectorstores.pinecone import Pinecone\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "import os\n",
        "import nltk\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import openai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "GNvcPz3L8i77"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input for URLs to build copilot on"
      ],
      "metadata": {
        "id": "rCxVY5w51oGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = []\n",
        "n_weblinks = int(input(\"How many web links you want the copilot to refer for response generation & insights? Enter here: \"))\n",
        "print(\"Enter your links below: \")\n",
        "for i in range(0, n_weblinks):\n",
        "  inp = input()\n",
        "  # appending the element in list\n",
        "  urls.append(inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uedatwOEroC",
        "outputId": "f5f41fee-9e27-4b01-e0c6-179620bdf1b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many web links you want the copilot to refer for response generation & insights? Enter here: 1\n",
            "Enter your links below: \n",
            "https://arxiv.org/pdf/2312.10997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading URL through LangChain's UnstructuredURLLoader"
      ],
      "metadata": {
        "id": "r4B7aLvJ1w2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "urls = loader.load()"
      ],
      "metadata": {
        "id": "1v6pfwRg8i5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a308d9b-b14f-4778-e2b1-0a10f4b4e824"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "ERROR:langchain_community.document_loaders.url:Error fetching or processing https://arxiv.org/pdf/2312.10997, exception: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging urls into a single list\n",
        "documents = []\n",
        "documents.extend(urls)"
      ],
      "metadata": {
        "id": "WCxahzx28i3g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGrRZrCtD3ZY",
        "outputId": "83fa23f7-f9a1-4483-c9b0-e5e1ae4ea153"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "texts"
      ],
      "metadata": {
        "id": "uxsrLG_U8i1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ea82c1-bb78-445b-d231-337432e808c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API Key Setting\n",
        "\n"
      ],
      "metadata": {
        "id": "dAt6MEyE17b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the OpenAI API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "ZQTZHqju8iy0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinecone API Setting"
      ],
      "metadata": {
        "id": "NK8hff9Q2Ask"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the pinecone key\n",
        "pc = Pinecone(api_key = userdata.get(\"PINECONE_API_KEY\"))\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"PINECONE_API_KEY\")"
      ],
      "metadata": {
        "id": "KbJqgcuP8iwe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a Pinecone index automatically if index doesn't exists\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "embeddings = OpenAIEmbeddings()\n",
        "index_name = 'myindex' #index name\n",
        "if index_name not in pc.list_indexes():\n",
        "    # Creating a new index\n",
        "    pc.create_index(name=index_name, metric=\"cosine\", dimension=1536,\n",
        "                    vector_type=\"dense\",\n",
        "                    spec=ServerlessSpec(\n",
        "                        cloud=\"aws\",\n",
        "                        region=\"us-east-1\"\n",
        "                    ))\n",
        "# The OpenAI embedding model 'text-embedding-ada-002 uses 1536 dimensions'\n",
        "docsearch = PineconeVectorStore.from_documents(texts, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "CazXFGiy8iuH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building and Execution"
      ],
      "metadata": {
        "id": "CTQOynAWmALD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4\", max_tokens=256)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=docsearch.as_retriever(),\n",
        "        verbose=True,\n",
        "        return_source_documents=True)"
      ],
      "metadata": {
        "id": "aHE6Ucpsxl-j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt = \"You are a researcher who is going to search the web links, summarize them and share insights as asked\""
      ],
      "metadata": {
        "id": "6SxPr2Xpyqf3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a RAG framework?\"\n",
        "result = qa({\"query\": query, \"prompt\": initial_prompt})"
      ],
      "metadata": {
        "id": "Ml9_APDWzOBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f77ddc-fecb-42c5-9030-c9514b2d7966"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYQAW7dQzP6A",
        "outputId": "367caeb4-2bcd-48a3-fa28-5ddec38cb3f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A RAG framework, or Red Amber Green framework, is a system used in project management to visually indicate the status or performance of various tasks or goals. Each color represents a different status: red typically indicates a problem or issue, amber suggests there may be a potential issue or delay, and green signifies that everything is on track. This system allows for quick, at-a-glance assessments of a project's progress.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['source_documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P602KahzR1N",
        "outputId": "e86c10a3-6ba7-4428-ee13-17857e3f0582"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    }
  ]
}